{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Volumes/Rohith/glove/glove.twitter.27B.200d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n",
    "glove = {key: val.values for key, val in df.T.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/rohith/Documents/College/Semester 4/Papers/NLP-COVID/WNUT-2020-Task-2-Dataset/train.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1241490299215634434</td>\n",
       "      <td>Official death toll from #covid19 in the Unite...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1245916400981381130</td>\n",
       "      <td>Dearest Mr. President @USER 1,169 coronavirus ...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1241132432402849793</td>\n",
       "      <td>Latest Updates March 20 ⚠️5274 new cases and 3...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1236107253666607104</td>\n",
       "      <td>真把公主不当干部 BREAKING: 21 people on Grand Princess...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1239673817552879619</td>\n",
       "      <td>OKLAHOMA CITY — The State Department of Educat...</td>\n",
       "      <td>UNINFORMATIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Id                                               Text  \\\n",
       "0  1241490299215634434  Official death toll from #covid19 in the Unite...   \n",
       "1  1245916400981381130  Dearest Mr. President @USER 1,169 coronavirus ...   \n",
       "2  1241132432402849793  Latest Updates March 20 ⚠️5274 new cases and 3...   \n",
       "3  1236107253666607104  真把公主不当干部 BREAKING: 21 people on Grand Princess...   \n",
       "4  1239673817552879619  OKLAHOMA CITY — The State Department of Educat...   \n",
       "\n",
       "           Label  \n",
       "0    INFORMATIVE  \n",
       "1    INFORMATIVE  \n",
       "2    INFORMATIVE  \n",
       "3    INFORMATIVE  \n",
       "4  UNINFORMATIVE  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text(df,col):\n",
    "  #Remove @ tags\n",
    "  comp_df = df.copy()\n",
    "    \n",
    "  # remove all the punctuation\n",
    "  comp_df[col] = comp_df[col].str.replace(r'(@\\w*)','')\n",
    "\n",
    "  #Remove URL\n",
    "  comp_df[col] = comp_df[col].str.replace(r\"http\\S+\", \"\")\n",
    "\n",
    "  #Remove # tag and the following words\n",
    "  comp_df[col] = comp_df[col].str.replace(r'#\\w+',\"\")\n",
    "\n",
    "  #Remove all non-character\n",
    "  comp_df[col] = comp_df[col].str.replace(r\"[^a-zA-Z ]\",\"\")\n",
    "\n",
    "  # Remove extra space\n",
    "  comp_df[col] = comp_df[col].str.replace(r'( +)',\" \")\n",
    "  comp_df[col] = comp_df[col].str.strip()\n",
    "\n",
    "  # Change to lowercase\n",
    "  comp_df[col] = comp_df[col].str.lower()\n",
    "\n",
    "  return comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_m = format_text(train,'Text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1241490299215634434</td>\n",
       "      <td>official death toll from in the united kingdom...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1245916400981381130</td>\n",
       "      <td>dearest mr president coronavirus deaths in the...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1241132432402849793</td>\n",
       "      <td>latest updates march new cases and new deaths ...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1236107253666607104</td>\n",
       "      <td>breaking people on grand princess cruise ship ...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1239673817552879619</td>\n",
       "      <td>oklahoma city the state department of educatio...</td>\n",
       "      <td>UNINFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1240790181860409344</td>\n",
       "      <td>democrats somehow managed to fight ebola witho...</td>\n",
       "      <td>UNINFORMATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1249147011003187200</td>\n",
       "      <td>as number of deaths surpassed worldwide ny sur...</td>\n",
       "      <td>INFORMATIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Id                                               Text  \\\n",
       "0  1241490299215634434  official death toll from in the united kingdom...   \n",
       "1  1245916400981381130  dearest mr president coronavirus deaths in the...   \n",
       "2  1241132432402849793  latest updates march new cases and new deaths ...   \n",
       "3  1236107253666607104  breaking people on grand princess cruise ship ...   \n",
       "4  1239673817552879619  oklahoma city the state department of educatio...   \n",
       "5  1240790181860409344  democrats somehow managed to fight ebola witho...   \n",
       "6  1249147011003187200  as number of deaths surpassed worldwide ny sur...   \n",
       "\n",
       "           Label  \n",
       "0    INFORMATIVE  \n",
       "1    INFORMATIVE  \n",
       "2    INFORMATIVE  \n",
       "3    INFORMATIVE  \n",
       "4  UNINFORMATIVE  \n",
       "5  UNINFORMATIVE  \n",
       "6    INFORMATIVE  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_m.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_m['Text']=train_m['Text'].str.replace('httpurl', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_X = train_m['Text'].tolist()\n",
    "Y_train = train_m['Label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(Y_train)\n",
    "Y_train = le.transform(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for i in range(len(X_X)):\n",
    "    vocab.append(word_tokenize(X_X[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros((len(vocab),size)) #Initializing the X matrix with zeros\n",
    "for i in range(len(vocab)):\n",
    "    emb = np.zeros((1,size))\n",
    "    for w in vocab[i]:\n",
    "        if w in glove.keys():\n",
    "            emb = emb +  glove[w]\n",
    "    X_train[i] = emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/Users/rohith/Documents/College/Semester 4/Papers/NLP-COVID/WNUT-2020-Task-2-Dataset/test.tsv',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_m = format_text(test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_m[1]=test_m[1].str.replace('httpurl', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_X_1 = test_m[1].tolist()\n",
    "Y_test = le.transform(test_m[2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = []\n",
    "for i in range(len(X_X_1)):\n",
    "    vocab.append(word_tokenize(X_X_1[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros((len(vocab),size)) #Initializing the X matrix with zeros\n",
    "for i in range(len(vocab)):\n",
    "    emb = np.zeros((1,size))\n",
    "    for w in vocab[i]:\n",
    "        if w in glove.keys():\n",
    "            emb = emb +  glove[w]\n",
    "    X_test[i] = emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    #MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "    KNeighborsClassifier(n_neighbors=3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.54      0.61       944\n",
      "           1       0.66      0.80      0.72      1056\n",
      "\n",
      "    accuracy                           0.68      2000\n",
      "   macro avg       0.68      0.67      0.67      2000\n",
      "weighted avg       0.68      0.68      0.67      2000\n",
      "\n",
      "0.6765\n",
      "------------------------------------------------------------\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.71       944\n",
      "           1       0.74      0.75      0.74      1056\n",
      "\n",
      "    accuracy                           0.73      2000\n",
      "   macro avg       0.73      0.72      0.72      2000\n",
      "weighted avg       0.73      0.73      0.73      2000\n",
      "\n",
      "0.726\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.76      0.67       944\n",
      "           1       0.72      0.55      0.63      1056\n",
      "\n",
      "    accuracy                           0.65      2000\n",
      "   macro avg       0.66      0.66      0.65      2000\n",
      "weighted avg       0.66      0.65      0.65      2000\n",
      "\n",
      "0.6505\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in models:\n",
    "    #model = RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0)\n",
    "    name = i.__class__.__name__\n",
    "    #Split Data \n",
    "\n",
    "    #Train Algorithm\n",
    "    i.fit(X_train, Y_train)\n",
    "\n",
    "    # Make Predictions\n",
    "    #y_pred_proba = i.predict_proba(X_test)\n",
    "    y_pred = i.predict(X_test)\n",
    "    print(name)\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "    print(accuracy_score(Y_test, y_pred))\n",
    "    print(\"------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vmdpy import VMD\n",
    "def maxvdm(f):\n",
    "    alpha = 1       \n",
    "    tau = 0            \n",
    "    K = 4         \n",
    "    DC = 0             \n",
    "    init = 1           \n",
    "    tol = 1e-7  \n",
    "    u, u_hat, omega = VMD(f, alpha, tau, K, DC, init, tol) \n",
    "    energy_array=[]\n",
    "    for i in u:\n",
    "        energy_array.append(energy(i))\n",
    "    ind = np.argmax(energy_array)\n",
    "    return u[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal\n",
    "def energy(u):\n",
    "# Estimate PSD `S_xx_welch` at discrete frequencies `f_welch`\n",
    "    f_welch, S_xx_welch = scipy.signal.welch(u)\n",
    "\n",
    "    # Integrate PSD over spectral bandwidth\n",
    "    # to obtain signal power `P_welch`\n",
    "    df_welch = f_welch[1] - f_welch[0]\n",
    "    return np.sum(S_xx_welch) * df_welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/scipy/signal/spectral.py:1961: UserWarning: nperseg = 256 is greater than input length  = 200, using nperseg = 200\n",
      "  warnings.warn('nperseg = {0:d} is greater than input length '\n"
     ]
    }
   ],
   "source": [
    "X_train_vmd = []\n",
    "for i in X_train:\n",
    "    X_train_vmd.append(maxvdm(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vmd = []\n",
    "for i in X_test:\n",
    "    X_test_vmd.append(maxvdm(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.44      0.53       944\n",
      "           1       0.61      0.79      0.69      1056\n",
      "\n",
      "    accuracy                           0.63      2000\n",
      "   macro avg       0.63      0.62      0.61      2000\n",
      "weighted avg       0.63      0.63      0.61      2000\n",
      "\n",
      "0.627\n",
      "------------------------------------------------------------\n",
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69       944\n",
      "           1       0.72      0.75      0.74      1056\n",
      "\n",
      "    accuracy                           0.72      2000\n",
      "   macro avg       0.72      0.71      0.71      2000\n",
      "weighted avg       0.72      0.72      0.72      2000\n",
      "\n",
      "0.716\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.67      0.62       944\n",
      "           1       0.66      0.57      0.61      1056\n",
      "\n",
      "    accuracy                           0.62      2000\n",
      "   macro avg       0.62      0.62      0.62      2000\n",
      "weighted avg       0.62      0.62      0.62      2000\n",
      "\n",
      "0.6185\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in models:\n",
    "    #model = RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0)\n",
    "    name = i.__class__.__name__\n",
    "    #Split Data \n",
    "\n",
    "    #Train Algorithm\n",
    "    i.fit(X_train_vmd, Y_train)\n",
    "\n",
    "    # Make Predictions\n",
    "    #y_pred_proba = i.predict_proba(X_test)\n",
    "    y_pred = i.predict(X_test_vmd)\n",
    "    print(name)\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "    print(accuracy_score(Y_test, y_pred))\n",
    "    print(\"------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python38064bit1060d4750c904259afeb7847dfa8ded2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
